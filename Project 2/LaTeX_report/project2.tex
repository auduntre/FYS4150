\documentclass[a4paper, fontsize=11pt]{article}

\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage[english]{babel} % English language/hyphenation
%\usepackage{hyperref}
\usepackage{listings}
\usepackage{color}
\usepackage{verbatim}
\usepackage{graphicx}

\usepackage[colorlinks=true,linkcolor=black,urlcolor=blue,
citecolor=blue]{hyperref}

%\bibliographystyle{ieeetr}
\bibliographystyle{apalike}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}


\lstset{frame=tb,
  language=C++,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\begin{document}

\title{Project 2 FYS4150 \\ Eigenvalue problems}
\author{Audun Tahina Reitan and Marius Holm}

%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------
\maketitle


\section{Abstract}



\section{Introduction}
In this project we'll develop code for solving eigenvalue problems. Our eigenvalue solver will be based on Jacobi's method, while the matrix we need to diagonalize is the tridiagonal Toeplitz matrix. This matrix has analytical eigenvalues and eigenvectors, which makes it easier for us to test our algorithms. 


\paragraph{}
The first problem we'll look at is the two-point boundary value problem of a buckling beam or a spring fastened at both ends. This problem has analytical solutions, and by adding a new variable along the diagonal we can study quantum mechanical problems. From quantum mechanics we will study the harmonic oscillator problem, with one or two electrons. For the two electron problem we can study the effects of Coulomb interaction and extract some interesting physics results.  The two electron problem even has analytical solutions for selected frequencies.\cite{PhysRevA.48.3561}

\paragraph{}
We introduce the relevant methods along with a brief explanation of our implementation.


Structure of report


\section{Methods}

\subsection{Jacobi's method}
Jacobi's method is a simple method for solving linear algebra problems of the sort

\begin{equation}
\hat{A} \textbf{x} = \textbf{b}
\end{equation}

where $\hat{A}$ is a matrix and \textbf{x} and \textbf{b} are vectors. The Jacobi method is an iterative scheme where we make a guess for the unknown, \textbf{x}, and after $k+1$ iterations we have

\begin{equation}
\textbf{x}^{(k+1)}=\hat{D}^{-1}(\textbf{b} - (\hat{L} + \hat{U}) \textbf{x}^{(k)})
\end{equation} 

where we have defined $\hat{A} = \hat{D} + \hat{U} + \hat{L}$. $\hat{D}$ is the diagonal matrix, $\hat{U}$ is an upper triangular matrix, and $\hat{L}$ is a lower triangular matrix.\cite{Jensen} 

\subsection{Eigenvalue problems}
Given the eigenvalue problem 

\begin{equation} \label{eigenvalue}
\textbf{A}\textbf{x}^{(v)}=\lambda^{(v)}\textbf{x}^{(v)}
\end{equation}

where \textbf{A} is a matrix of dimension $n$. We also have that $\lambda^{(v)}$ are the eigenvalues and $\textbf{x}^{(v)}$ the corresponding eigenvectors. From this we find that the eigenvalues of \textbf{A} are given by the $n$ roots of the characteristic polynomial given by:

\begin{equation}
P(\lambda)=\det(\lambda \textbf{I} - \textbf{A}) = \prod^{n}_{i=1}(\lambda_{i} - \lambda)
\end{equation}

This procedure is only valid for problems where we only need a small fraction of the eigenvalues and eigenvectors, or if the matrix is on a tridiagonal form. As our matrix is tridiagonal we can use the above procedure which leads us to the Jacobi method. A general procedure for solving equation \eqref{eigenvalue} is to perform similarity transformations until the original matrix \textbf{A} is either on diagonal form or is a tridiagonal matrix which then easily can be diagonalized. The general procedure leads to the well known Householder's algorithm.\cite{Jensen}


\subsection{Jacobi's method}
Given an $n \times n$ orthogonal transformation matrix

\begin{equation}
\textbf{S} =
\begin{pmatrix}
1 & 0 & \hdots & 0 & 0 & \hdots & 0 & 0 \\
0 & 1 & \hdots & 0 & 0 & \hdots & 0 & 0 \\
\hdots & \hdots & \hdots & \hdots & \hdots & \hdots & 0 & \hdots \\ 
0 & 0 & \hdots & \cos \theta & 0 & \hdots & 0 & \sin \theta \\
0 & 0 & \hdots & 0 & 1 & \hdots & 0 & 0 \\
\hdots & \hdots & \hdots & \hdots & \hdots & \hdots & 0 & \hdots \\
0 & 0 & \hdots & 0 & 0 & \hdots & 1 & 0 \\ 
0 & 0 & \hdots & \sin \theta & \hdots & \hdots & 0 & \cos \theta \\
\end{pmatrix}
\end{equation}

with the property $\textbf{S}^{\textbf{T}}=\textbf{S}^{-\textbf{1}}$. This matrix performs a plane rotation around an angle $\theta$ in the Euclidean $n$-dimensional space. Which means that the non-zero matrix elements are given by
\begin{equation}
s_{kk}=s_{ll}=\cos \theta, \:\: s_{kl}=-s_{lk}=-\sin \theta, \:\: s_{ii}=-s_{ii}=1 \quad i \neq k \: \: i \neq l,
\end{equation}

A similarity transformation 

\begin{equation}
\textbf{B}=\textbf{S}_{u\textbf{T}} \textbf{A} \textbf{S},
\end{equation}

results in 

\begin{flalign*}
b_{ii} &= a_{ii}, \: i \neq k, i\neq l 
\\
b_{ik} &= a_{ik} \cos \theta - a_{il} \sin \theta, \: i \neq k, i\neq l 
\\
b_{il} &= a_{il} \cos \theta + a_{ik} \sin \theta, \: i \neq k, i\neq l 
\\
b_{kk} &= a_{kk} \cos^{2} \theta - 2 a_{kl} \cos \theta \, \sin \theta + 		a_{ll} \sin^{2} \theta 
\\
b_{ll} &= a_{all} \cos^{2} \theta + 2 a_{kl} \cos \theta \, \sin \theta + 		a_{kk} \sin^{2} \theta 
\\
b_{kl} &= (a_{kk} - a_{ll}) \cos \theta \, \sin \theta + a_{kl} (\cos^{2} \theta - sin^{2} \theta)
\end{flalign*}

We can choose the angle $\theta$ as we wish, while making sure that all the non-diagonal matrix elements, $b_{kl}$ become zero. The algorithm which follows is then quite simple. We do a number of similarity transformations until the sum over the squared non-diagonal matrix elements are less than some chosen tolerance, typically less than $10^{-8}$. We therefore seek to minimize

\begin{equation}
\text{off}(\textbf{A}) = \sqrt{\sum^{n}_{i=1} \sum^{n}_{j=1, \: j \neq i} a_{ij}^{2}}
\end{equation}



\subsection{Scaling equations}
\paragraph{Transformation matrix}

For Jacobi's method the the rotational elements $\sin \theta = s$ and $\cos \theta = c$ with $\tan \theta = t = s / c$ is given by:

\begin{equation}
\cot 2\theta = \tau = \frac{a_{ll} - a_{kk}}{2 a_{kl}}
\end{equation}

\begin{equation}
\cot 2\theta = \frac{1}{2}\left(\cot \theta - \tan \theta \right) \implies t^2 + 2 \tau t - 1 = 0 \implies t = -\tau \pm \sqrt{1 + \tau^2} 
\end{equation}

\begin{equation}
c = \frac{1}{\sqrt{1+ t^2}}
\end{equation}

\begin{equation}
s = t\,c
\end{equation}

For $t$ we choose the solution to the 2nd degree formula that returns the smallest answer so that $t$ does not reach very high values. We do this because of the risk for loss of significance because of cancellation in the equation for $t$ when $\tau$ becomes so big that $\sqrt{1 + \tau^2} \approx \tau $.

\begin{equation}
t = \frac{1}{\tau + \sqrt{1 + \tau^2}}, \quad \tau > 0.0
\end{equation}

\begin{equation}
t = \frac{-1}{-\tau + \sqrt{1 + \tau^2}}, \quad \tau \leq 0.0
\end{equation}

These two solutions are equivalent to the smallest solution of the 2nd degree equation, and are numerical stable.

\paragraph{Quantum mechanics}
We are also interested in quantum mechanical problems where we want to solve the radial part of Schr\"{o}dinger's equation for one electron in a harmonic oscillator potential. The equation is given as:

\begin{equation}
-\dfrac{\hbar^2}{2m}\Big(\dfrac{1}{r^2} \dfrac{d}{dr} r^2 \dfrac{d}{dr} - \dfrac{l(l+1)}{r^2} \Big) R(r) +V(r)R(r)=E \, R(r)
\end{equation}

$V(r)$ for a harmonic oscillator potential is given as $V(r)=\frac{1}{2}kr^2$ with \\$k=m \omega^2$ and where $E$ is the energy of the harmonic oscillator in three dimensions. $\omega$ is the oscillator frequency, and the energies are given as:

\begin{equation}
E_{nl} = \hbar \omega \Big(2n+l+\frac{3}{2} \Big), \: \text{with} \: n=0,1,2, \hdots \: \text{and} \: l=0,1,2,\hdots
\end{equation}

Since we have made the transformation into spherical coordinates we have $r \in [0, \infty)$, and the quantum number $l$ is the orbital momentum of the electron. We then substitute $R(r)=\dfrac{1}{r}u(r)$ and get

\begin{equation}
\dfrac{\hbar^2}{2m} \dfrac{d^2}{dr^2} u(r) + \Big(V(r) + \dfrac{l(l+1)}{r^2} \dfrac{\hbar^2}{2m}\Big) u(r) = E \, u(r)
\end{equation}

With boundary conditions $u(0)=0$ and $u(\infty)=0$. We introduce the dimensionless variable $\rho = (1/\alpha)r$ where $\alpha$ is a constant with dimension length. We set $l=0$, and insert $V(\rho)=(1/2)k\alpha^2 \rho^2$. This gives us the following equation

\begin{equation}
-\dfrac{\hbar^2}{2m\alpha^2} \dfrac{d^2}{d\rho^2} \, u(\rho) + \dfrac{k}{2} \alpha^2 \rho^2 \, u(\rho) = E \, u(\rho) \quad |\cdot \dfrac{2m\alpha^2}{\hbar^2}
\end{equation}

\begin{equation}
-\dfrac{d^2}{d\rho^2} \, u(\rho) + \dfrac{mk}{\hbar^2} \alpha^4 \rho^2 \, u(\rho) = \dfrac{2m\alpha^2}{\hbar^2} E \, u(\rho) 
\end{equation}

Fixing the constant $\alpha$ as 

\begin{equation}
\alpha=\Big(\dfrac{\hbar^2}{mk}\Big)^{\frac{1}{4}}
\end{equation} 

We also define $\lambda=\dfrac{2m\alpha^2}{\hbar^2}E$ which lets us write the Schr\"{o}dinger equation as

\begin{equation}
-\dfrac{d^2}{d\rho^2}u(\rho) + \rho^2 \, u(\rho) = \lambda \, u(\rho)
\end{equation}

A lot of the same steps as above are repeated for the problem considering quantum dots in three dimensions with two electrons. I will therefore only state the final result along with the necessary constants that are defined. We then find the Schr\"{o}dinger equation as:

\begin{equation}
-\dfrac{d^2}{d\rho^2}\psi(\rho) + \omega^2_{r}\rho^2 \, u(\rho) + \frac{1}{\rho} = \lambda \, \psi(\rho)
\end{equation}

where we have defined  $\omega_{r}^2$ as

\begin{equation}
\omega^2_{r}=\dfrac{1}{4} \dfrac{mk}{\hbar^2} \alpha^4
\end{equation}

and fixing $\alpha$ by requiring 

\begin{equation}
\alpha = \dfrac{\hbar^2}{m\beta e^2}.
\end{equation}

Finally we have defined $\lambda$ as

\begin{equation}
\lambda=\dfrac{m\alpha^2}{\hbar^2}E
\end{equation}



\subsection{Implementation}

All our code, benchmark calculations, and plots used can be found in \href{https://github.com/auduntre/FYS4150/tree/master/Project%202}{Auduns GitHub}.

\section{Results}
\subsection{Preservation of dot product}
We want to show that an orthogonal transformation preserves the dot product and orthogonality. Given a basis of vectors $\textbf{v}_{i}$

\begin{equation}
\textbf{v}_{i}=
\begin{bmatrix}
v_{i1} \\
v_{i2} \\
\vdots \\
v_{in}
\end{bmatrix}
\end{equation}

And assuming that the basis is orthogonal.

\begin{equation}2
\textbf{v}^{T}_{j} \textbf{v}_{i} = \delta_{ij}
\end{equation}

The transformation is given by

\begin{equation}
\textbf{w}_{i} = \textbf{U} \textbf{v}_{i}
\end{equation}

As the transformation matrix \textbf{U} is orthogonal we have $\textbf{U}^{T}\textbf{U} = \textbf{I}$.

\begin{align*}
\textbf{w}_{i} \cdot \textbf{w}_{j} & =\textbf{U} \textbf{v}_{i} \cdot \textbf{U} \textbf{v}_{j} = (\textbf{U}\textbf{v}_{i})^{T}(\textbf{U}\textbf{v}_{j})=(\textbf{U}^{T} \textbf{v}_{i}^{T})(\textbf{U}\textbf{v}_{j})\\
&= \textbf{v}_{i}^{T} (\textbf{U}^{T} \textbf{U}) \textbf{v}_{j}= \textbf{v}_{i}^{T} \, \textbf{I} \, \textbf{v}_{j} =  \textbf{v}_{i}^{T} \,  \textbf{v}_{j} = \textbf{v}_{i} \cdot \textbf{v}_{j} = \textbf{v}^T_{i} \textbf{v}_{j}
\end{align*}

As $\textbf{w}_{i} \cdot \textbf{w}_{j} = \textbf{v}_{i} \cdot \textbf{v}_{j}$ the dot product is preserved. The same applies for $\textbf{v}_{i} \cdot \textbf{v}_{j} = \textbf{v}^T_{i} \textbf{v}_{j} = \delta_{ij}$ which implies that orthogonality is also preserved.

\subsection{Eigenvalues}

Include results of $\text{error}=\lambda_{\text{real}} - \lambda_{\text{model}}$

\section{Discussion}
\subsection{Jacobi method}
The Jacobi method is generally a slower algorithm than those based tridiagonalization. However the Jacobi method is easy to parallelize which can improve performance significantly. The main reason for the Jacobi methods slow convergence is that for each new rotation, matrix elements which were zero might change to non-zero values.


\section{Appendix A}

\newpage

\bibliography{references}
\end{document}